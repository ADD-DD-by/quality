# app.py
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots  # ä½ åŸæœ¬æœ‰å¼•å…¥ï¼Œä¿ç•™ä¸åŠ¨

st.set_page_config(page_title="v0.7 å®¢è¯‰åˆ†æçœ‹æ¿", layout="wide")

# =========================
# å·¥å…·å‡½æ•°
# =========================
def _try_parse_datetime(s: pd.Series) -> pd.Series:
    """è§£ææ—¶é—´å­—æ®µï¼Œä¼˜å…ˆæ”¯æŒ YYYYMMDDï¼ˆå¦‚ 20260102ï¼‰ï¼Œå¤±è´¥å†ç”¨è‡ªåŠ¨è§£æå…œåº•"""
    if s is None:
        return s

    # å…ˆæŒ‰ YYYYMMDD å¼ºåˆ¶è§£æ
    out = pd.to_datetime(s, format="%Y%m%d", errors="coerce")

    # æœªè§£ææˆåŠŸçš„å†è‡ªåŠ¨å…œåº•
    mask = out.isna()
    if mask.any():
        out.loc[mask] = pd.to_datetime(
            s.loc[mask], errors="coerce", infer_datetime_format=True
        )

    return out


def _read_excel(uploaded_file) -> pd.DataFrame:
    return pd.read_excel(uploaded_file)


def _safe_str_series(s: pd.Series) -> pd.Series:
    return s.astype(str).fillna("")


def _starts_with_v07(s: pd.Series) -> pd.Series:
    # ä»¥ v0.7 å¼€å¤´ï¼ˆå¿½ç•¥å¤§å°å†™ã€å‰åç©ºæ ¼ï¼‰
    t = _safe_str_series(s).str.strip().str.lower()
    return t.str.startswith("v0.7")


def _make_beautiful_pie(df: pd.DataFrame, name_col: str, value_col: str, title: str, max_categories=10):
    """
    ç»˜åˆ¶ç¾è§‚çš„é¥¼å›¾
    """
    tmp = df[[name_col, value_col]].copy()
    tmp[name_col] = tmp[name_col].fillna("æœªå¡«å†™")
    tmp[value_col] = pd.to_numeric(tmp[value_col], errors="coerce").fillna(0)

    # åˆ†ç»„æ±‡æ€»
    grouped = (
        tmp.groupby(name_col, as_index=False)[value_col]
        .sum()
        .sort_values(value_col, ascending=False)
    )

    total_value = grouped[value_col].sum()

    if total_value <= 0:
        st.info(f"{title}ï¼šå½“å‰ç­›é€‰ä¸‹ {value_col} å…¨ä¸º 0 / ç©ºï¼Œæ— æ³•ç»˜å›¾ã€‚")
        return None

    # å¦‚æœç±»åˆ«å¤ªå¤šï¼Œåˆå¹¶å°ç±»åˆ«ä¸º"å…¶ä»–"
    if len(grouped) > max_categories:
        top_n = grouped.iloc[:max_categories-1]
        others = grouped.iloc[max_categories-1:]
        others_sum = others[value_col].sum()

        if others_sum > 0:
            others_row = pd.DataFrame({
                name_col: ["å…¶ä»–"],
                value_col: [others_sum]
            })
            grouped = pd.concat([top_n, others_row], ignore_index=True)
        else:
            grouped = top_n

    # ä½¿ç”¨ä¸“ä¸šçš„é…è‰²æ–¹æ¡ˆï¼ˆPlotly é»˜è®¤çš„ Set3 è‰²ç³»ï¼Œé€‚åˆåˆ†ç±»æ•°æ®ï¼‰
    colors = px.colors.qualitative.Set3

    # åˆ›å»ºé¥¼å›¾
    fig = go.Figure()

    labels = grouped[name_col].tolist()
    values = grouped[value_col].tolist()

    fig.add_trace(go.Pie(
        labels=labels,
        values=values,
        hoverinfo="text",
        text=labels,
        textinfo="percent+label",
        textposition="inside",
        insidetextorientation="radial",
        hole=0.4,
        marker=dict(
            colors=colors[:len(labels)],
            line=dict(color='white', width=2)
        ),
        hovertemplate="%{text}<br>é—®é¢˜æ•°: %{value:,.0f}<br>å æ¯”: %{percent:.1%}<extra></extra>",
        sort=False
    ))

    # ç¾åŒ–å¸ƒå±€
    fig.update_layout(
        title=dict(
            text=title,
            font=dict(size=16, family="Arial, sans-serif"),
            x=0.5,
            xanchor="center"
        ),
        showlegend=True,
        legend=dict(
            orientation="v",
            yanchor="middle",
            y=0.5,
            xanchor="left",
            x=1.05,
            font=dict(size=10),
            bgcolor="rgba(255,255,255,0.8)",
            bordercolor="lightgray",
            borderwidth=1
        ),
        margin=dict(t=50, b=20, l=20, r=150),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        annotations=[
            dict(
                text=f"æ€»è®¡: {total_value:,.0f}",
                showarrow=False,
                x=0.5,
                y=0.5,
                font=dict(size=14, color="gray")
            )
        ]
    )

    fig.update_traces(
        textfont=dict(
            size=11,
            family="Arial, sans-serif"
        ),
        outsidetextfont=dict(size=10)
    )

    return fig


def _create_problem_hierarchy_chart(filtered_df):
    """
    åˆ›å»ºé—®é¢˜å±‚çº§æ¡‘åŸºå›¾ï¼ˆä¸€çº§é—®é¢˜ -> äºŒçº§é—®é¢˜ï¼‰
    """
    if len(filtered_df) == 0:
        return None

    # å‡†å¤‡æ•°æ®
    tmp = filtered_df.copy()
    tmp["ä¸€çº§é—®é¢˜åç§°"] = tmp["ä¸€çº§é—®é¢˜åç§°"].fillna("æœªå¡«å†™")
    tmp["äºŒçº§é—®é¢˜åç§°"] = tmp["äºŒçº§é—®é¢˜åç§°"].fillna("æœªå¡«å†™")
    tmp["é—®é¢˜æ•°"] = pd.to_numeric(tmp["é—®é¢˜æ•°"], errors="coerce").fillna(0)

    # æ±‡æ€»ä¸€çº§åˆ°äºŒçº§çš„é—®é¢˜æ•°
    hierarchy_df = (
        tmp.groupby(["ä¸€çº§é—®é¢˜åç§°", "äºŒçº§é—®é¢˜åç§°"])
        .agg(é—®é¢˜æ•°=("é—®é¢˜æ•°", "sum"))
        .reset_index()
    )

    hierarchy_df = hierarchy_df[hierarchy_df["é—®é¢˜æ•°"] > 0]
    if len(hierarchy_df) == 0:
        return None

    # èŠ‚ç‚¹
    level1_nodes = hierarchy_df["ä¸€çº§é—®é¢˜åç§°"].unique().tolist()
    level2_nodes = hierarchy_df["äºŒçº§é—®é¢˜åç§°"].unique().tolist()
    all_nodes = level1_nodes + level2_nodes

    node_indices = {node: i for i, node in enumerate(all_nodes)}

    source = [node_indices[row["ä¸€çº§é—®é¢˜åç§°"]] for _, row in hierarchy_df.iterrows()]
    target = [node_indices[row["äºŒçº§é—®é¢˜åç§°"]] for _, row in hierarchy_df.iterrows()]
    value = [row["é—®é¢˜æ•°"] for _, row in hierarchy_df.iterrows()]

    # âœ… ä¿®å¤ç‚¹1ï¼šnode ä¸æ”¯æŒ font å±æ€§ï¼Œåˆ é™¤ node.font
    fig = go.Figure(data=[go.Sankey(
        arrangement="snap",
        node=dict(
            pad=18,
            thickness=22,
            line=dict(color="black", width=0.5),
            label=all_nodes,
            color=px.colors.qualitative.Set3 * (len(all_nodes) // len(px.colors.qualitative.Set3) + 1)
        ),
        link=dict(
            source=source,
            target=target,
            value=value,
            hovertemplate="%{source.label} â†’ %{target.label}<br>é—®é¢˜æ•°: %{value:,.0f}<extra></extra>"
        )
    )])

    # âœ… ä¿®å¤ç‚¹2ï¼šç”¨ layout font æ§åˆ¶æ•´ä½“å­—ä½“å˜å¤§ï¼ˆé»˜è®¤ä¸åŠ ç²—ï¼‰
    fig.update_layout(
        title=dict(
            text="é—®é¢˜å±‚çº§å…³ç³»å›¾ï¼ˆä¸€çº§é—®é¢˜ â†’ äºŒçº§é—®é¢˜ï¼‰",
            font=dict(size=18, family="Arial, sans-serif"),
            x=0.5,
            xanchor="center"
        ),
        font=dict(
            size=14,                 # å­—ä½“æ›´å¤§
            family="Arial, sans-serif",
            color="#333"
        ),
        margin=dict(t=60, b=20, l=20, r=20),
        height=520
    )

    # âœ… åˆ«å¿˜äº† return
    return fig


# =========================
# é¡µé¢
# =========================
st.title("ğŸ“Œ v0.7 æ¬¾å¼å®¢è¯‰åˆ†æ")
st.markdown("""
- **å…¨å±€ç­›é€‰**ï¼šæ—¶é—´èŒƒå›´ï¼ˆæŒ‰ å¹³å°è®¢å•æ—¶é—´(day)ï¼‰ã€ç«™ç‚¹ã€erpskuæ¬¾å¼åç§°ï¼ˆå¤šé€‰ï¼‰
- **å›¾è¡¨äº¤äº’**ï¼šæ‰€æœ‰å›¾è¡¨å‡å¯æ‚¬åœæŸ¥çœ‹è¯¦æƒ…ï¼Œç‚¹å‡»å›¾ä¾‹å¯ç­›é€‰
""")

with st.sidebar:
    st.header("â‘  ä¸Šä¼ ä¸»æ•°æ®ï¼ˆExcelï¼‰")
    main_file = st.file_uploader("ä¸Šä¼  Excelï¼ˆä¸»æ•°æ®ï¼‰", type=["xlsx", "xls"])

    st.divider()
    st.header("â‘¡ æ”¹è¿›æƒ…å†µæ•°æ®ä¸Šä¼ ")
    extra_file = st.file_uploader("ä¸Šä¼  Excelï¼ˆé¢å¤–å±•ç¤ºç”¨ï¼‰", type=["xlsx", "xls"], key="extra")

# =========================
# é¢å¤–è¡¨å±•ç¤º
# =========================
if extra_file is not None:
    try:
        extra_df = _read_excel(extra_file)
        st.subheader("ğŸ“ æ”¹è¿›æ–¹æ¡ˆ")
        st.dataframe(extra_df, use_container_width=True, height=520)
    except Exception as e:
        st.error(f"é¢å¤–è¡¨è¯»å–å¤±è´¥ï¼š{e}")
    st.divider()

# =========================
# ä¸»æ•°æ®åˆ†æ
# =========================
if main_file is None:
    st.warning("è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ ä¸»æ•°æ® Excelã€‚")
    st.stop()

try:
    df = _read_excel(main_file)
except Exception as e:
    st.error(f"ä¸»æ•°æ®è¯»å–å¤±è´¥ï¼š{e}")
    st.stop()

# å¿…è¦å­—æ®µæ£€æŸ¥
required_cols = [
    "è®¢å•å‚è€ƒå·",
    "å¹³å°è®¢å•æ—¶é—´(day)",
    "ç«™ç‚¹",
    "erpskuæ¬¾å¼åç§°",
    "erp sku",
    "é—®é¢˜æ•°",
    "ä¸€çº§é—®é¢˜åç§°",
    "äºŒçº§é—®é¢˜åç§°",
]
missing = [c for c in required_cols if c not in df.columns]
if missing:
    st.error(f"ä¸»æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µï¼š{missing}")
    st.stop()

# =========================
# 1) å¼ºåˆ¶ç­›é€‰ v0.7
# =========================
df = df.copy()
df = df[_starts_with_v07(df["erpskuæ¬¾å¼åç§°"])].copy()
st.caption(f"âœ… å·²ç­›é€‰ï¼šerpskuæ¬¾å¼åç§° ä»¥ v0.7 å¼€å¤´ï¼ˆå½“å‰ {len(df):,} è¡Œï¼‰")

# =========================
# 2) æ—¶é—´å­—æ®µå¤„ç†ï¼ˆYYYYMMDDï¼‰
# =========================
df["_order_time"] = _try_parse_datetime(df["å¹³å°è®¢å•æ—¶é—´(day)"])
time_parse_ok = df["_order_time"].notna().sum()
if time_parse_ok == 0:
    st.warning("âš ï¸ å¹³å°è®¢å•æ—¶é—´(day) æ— æ³•è§£æä¸ºæ—¥æœŸï¼Œæ—¶é—´ç­›é€‰ä¸å¯ç”¨ã€‚")

# =========================
# 3) å…¨å±€ç­›é€‰
# =========================
with st.sidebar:
    st.divider()
    st.header("â‘¢ å…¨å±€ç­›é€‰")

    if time_parse_ok > 0:
        tmin = df["_order_time"].min()
        tmax = df["_order_time"].max()
        date_range = st.date_input(
            "æ—¶é—´èŒƒå›´ï¼ˆå¹³å°è®¢å•æ—¶é—´ï¼‰",
            value=(tmin.date(), tmax.date()),
            min_value=tmin.date(),
            max_value=tmax.date(),
        )
    else:
        date_range = None
        st.info("æ—¶é—´åˆ—ä¸å¯è§£æï¼Œå·²è·³è¿‡æ—¶é—´ç­›é€‰")

    site_options = sorted(df["ç«™ç‚¹"].dropna().unique().tolist())
    selected_sites = st.multiselect("ç«™ç‚¹ï¼ˆå¤šé€‰ï¼‰", site_options, default=site_options)

    style_options = sorted(df["erpskuæ¬¾å¼åç§°"].dropna().unique().tolist())
    selected_styles = st.multiselect("erpskuæ¬¾å¼åç§°ï¼ˆå¤šé€‰ï¼‰", style_options, default=style_options)

# =========================
# 4) åº”ç”¨ç­›é€‰
# =========================
filtered = df.copy()

if date_range is not None and time_parse_ok > 0:
    start_date, end_date = date_range
    start_dt = pd.to_datetime(start_date)
    end_dt = pd.to_datetime(end_date) + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)
    filtered = filtered[
        (filtered["_order_time"] >= start_dt) & (filtered["_order_time"] <= end_dt)
    ]

if selected_sites:
    filtered = filtered[filtered["ç«™ç‚¹"].isin(selected_sites)]
else:
    filtered = filtered.iloc[0:0]

if selected_styles:
    filtered = filtered[filtered["erpskuæ¬¾å¼åç§°"].isin(selected_styles)]
else:
    filtered = filtered.iloc[0:0]

# =========================
# KPI
# =========================
filtered["é—®é¢˜æ•°"] = pd.to_numeric(filtered["é—®é¢˜æ•°"], errors="coerce").fillna(0)

st.subheader("ğŸ“ˆ å…³é”®æŒ‡æ ‡æ¦‚è§ˆ")
kpi_cols = st.columns(4)

with kpi_cols[0]:
    st.metric(label="ç­›é€‰åè¡Œæ•°", value=f"{len(filtered):,}", delta=None)

with kpi_cols[1]:
    st.metric(label="è®¢å•æ•°", value=f"{filtered['è®¢å•å‚è€ƒå·'].nunique():,}", delta=None)

with kpi_cols[2]:
    st.metric(label="ERP SKU æ•°", value=f"{filtered['erp sku'].nunique():,}", delta=None)

with kpi_cols[3]:
    total_problems = filtered["é—®é¢˜æ•°"].sum()
    st.metric(label="æ€»é—®é¢˜æ•°", value=f"{total_problems:,.0f}", delta=None)

st.divider()

# =========================
# ç»Ÿè®¡è¡¨ï¼ˆå« erpskuå®¢è¯‰ç‡ï¼‰
# =========================
st.subheader("ç»Ÿè®¡è¡¨ï¼ˆæŒ‰ erpskuæ¬¾å¼åç§°ï¼‰")
tmp = filtered.copy()
tmp["_pair"] = tmp["è®¢å•å‚è€ƒå·"].astype(str) + "||" + tmp["erp sku"].astype(str)

summary = (
    tmp.groupby("erpskuæ¬¾å¼åç§°", as_index=False)
    .agg(
        é”€å”®æ•°é‡=("_pair", pd.Series.nunique),
        é—®é¢˜æ•°=("é—®é¢˜æ•°", "sum"),
    )
)

summary["erpskuå®¢è¯‰ç‡"] = np.where(
    summary["é”€å”®æ•°é‡"] > 0,
    summary["é—®é¢˜æ•°"] / summary["é”€å”®æ•°é‡"],
    0
)
summary["erpskuå®¢è¯‰ç‡"] = summary["erpskuå®¢è¯‰ç‡"].round(4)
summary["å®¢è¯‰ç‡(%)"] = (summary["erpskuå®¢è¯‰ç‡"] * 100).round(2)

summary = summary.sort_values(
    ["erpskuå®¢è¯‰ç‡", "é—®é¢˜æ•°", "é”€å”®æ•°é‡"],
    ascending=[False, False, True]
)

display_summary = summary.copy()
display_summary["é”€å”®æ•°é‡"] = display_summary["é”€å”®æ•°é‡"].apply(lambda x: f"{x:,}")
display_summary["é—®é¢˜æ•°"] = display_summary["é—®é¢˜æ•°"].apply(lambda x: f"{x:,}")
display_summary["å®¢è¯‰ç‡(%)"] = display_summary["å®¢è¯‰ç‡(%)"].apply(lambda x: f"{x:.2f}%")

st.dataframe(
    display_summary[["erpskuæ¬¾å¼åç§°", "é”€å”®æ•°é‡", "é—®é¢˜æ•°", "å®¢è¯‰ç‡(%)"]],
    use_container_width=True,
    height=420,
    column_config={
        "erpskuæ¬¾å¼åç§°": "æ¬¾å¼åç§°",
        "é”€å”®æ•°é‡": "é”€å”®æ•°é‡",
        "é—®é¢˜æ•°": "é—®é¢˜æ•°",
        "å®¢è¯‰ç‡(%)": "å®¢è¯‰ç‡"
    }
)

st.divider()

# =========================
# é—®é¢˜åˆ†æå›¾è¡¨
# =========================
st.subheader("ğŸ“Š é—®é¢˜åˆ†æ")

col1, col2 = st.columns(2)

with col1:
    fig1 = _make_beautiful_pie(
        filtered,
        name_col="ä¸€çº§é—®é¢˜åç§°",
        value_col="é—®é¢˜æ•°",
        title="ä¸€çº§é—®é¢˜åˆ†å¸ƒ"
    )
    if fig1:
        st.plotly_chart(fig1, use_container_width=True)
    else:
        st.info("æš‚æ— ä¸€çº§é—®é¢˜æ•°æ®")

with col2:
    fig2 = _make_beautiful_pie(
        filtered,
        name_col="äºŒçº§é—®é¢˜åç§°",
        value_col="é—®é¢˜æ•°",
        title="äºŒçº§é—®é¢˜åˆ†å¸ƒ"
    )
    if fig2:
        st.plotly_chart(fig2, use_container_width=True)
    else:
        st.info("æš‚æ— äºŒçº§é—®é¢˜æ•°æ®")

st.subheader("ğŸ”— é—®é¢˜å±‚çº§å…³ç³»")
sankey_fig = _create_problem_hierarchy_chart(filtered)
if sankey_fig:
    st.plotly_chart(sankey_fig, use_container_width=True)
else:
    st.info("æš‚æ— å±‚çº§å…³ç³»æ•°æ®")

st.divider()

# =========================
# ä¸€çº§ / äºŒçº§é—®é¢˜æ•°æ’è¡Œ
# =========================
st.subheader("ğŸ·ï¸ é—®é¢˜æ•°æ’è¡Œ")

rank_col1, rank_col2 = st.columns(2)

with rank_col1:
    st.markdown("#### ä¸€çº§é—®é¢˜æ•°æ’è¡Œï¼ˆTop 10ï¼‰")
    l1_rank = (
        filtered.groupby("ä¸€çº§é—®é¢˜åç§°", as_index=False)
        .agg(é—®é¢˜æ•°=("é—®é¢˜æ•°", "sum"))
        .sort_values("é—®é¢˜æ•°", ascending=False)
        .head(10)
    )
    l1_rank["é—®é¢˜æ•°"] = l1_rank["é—®é¢˜æ•°"].astype(int)
    st.dataframe(l1_rank, use_container_width=True, height=360)

with rank_col2:
    st.markdown("#### äºŒçº§é—®é¢˜æ•°æ’è¡Œï¼ˆTop 10ï¼‰")
    l2_rank = (
        filtered.groupby("äºŒçº§é—®é¢˜åç§°", as_index=False)
        .agg(é—®é¢˜æ•°=("é—®é¢˜æ•°", "sum"))
        .sort_values("é—®é¢˜æ•°", ascending=False)
        .head(10)
    )
    l2_rank["é—®é¢˜æ•°"] = l2_rank["é—®é¢˜æ•°"].astype(int)
    st.dataframe(l2_rank, use_container_width=True, height=360)

# =========================
# æ˜ç»†å±•ç¤º
# =========================
with st.expander("ğŸ“‹ æŸ¥çœ‹ç­›é€‰åçš„æ˜ç»†æ•°æ®", expanded=False):
    st.dataframe(
        filtered.drop(columns=["_order_time", "_pair"], errors="ignore"),
        use_container_width=True,
        height=520,
    )

# =========================
# æ ·å¼ä¼˜åŒ–
# =========================
st.markdown("""
<style>
    /* ç¾åŒ–metricå¡ç‰‡ */
    [data-testid="stMetric"] {
        background-color: #f8f9fa;
        padding: 20px;
        border-radius: 10px;
        border-left: 5px solid #1e88e5;
    }

    [data-testid="stMetricLabel"] {
        color: #666;
        font-size: 14px;
    }

    [data-testid="stMetricValue"] {
        color: #1e88e5;
        font-size: 24px;
        font-weight: bold;
    }

    /* ç¾åŒ–å±•å¼€å™¨ */
    .streamlit-expanderHeader {
        background-color: #f0f2f6;
        border-radius: 5px;
    }

    /* ç¾åŒ–åˆ†éš”çº¿ */
    hr {
        margin: 2rem 0;
        border: none;
        height: 1px;
        background: linear-gradient(to right, transparent, #ddd, transparent);
    }
</style>
""", unsafe_allow_html=True)
